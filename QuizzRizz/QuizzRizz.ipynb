{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlqOZZ1B9dkl"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!apt-get install tesseract-ocr\n",
        "!apt-get install pciutils\n",
        "!pip install pytesseract Pillow discord langchain_community colab-xterm\n",
        "\n",
        "#@markdown <br><center><h3><font color=white><b>üõ†Ô∏è INSTALL DEPENDENCIES üõ†Ô∏è</b></h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueafhMFU9oBt",
        "outputId": "23dcac99-cc00-4577-83d3-aa801214136c"
      },
      "outputs": [],
      "source": [
        "#@markdown <br><center><h2><font color=white><b>üì• Download Ollama Models üì•</b></h2>\n",
        "#@markdown <br><center><h4><font color=\"white\">```ollama serve & ollama run llama3```</center></br></h4>\n",
        "#@markdown <br><center><font color=red>NOTE:<font color=white> You can run any model you want. Just go to the link below and try whichever model you prefer. Don't forget to update the model in the code below.</br>\n",
        "#@markdown <br><center><font color=white>MORE MODELS : https://ollama.com/library</br>\n",
        "\n",
        "%load_ext colabxterm\n",
        "%xterm\n",
        "!curl -faSL https://ollama.ai/install.sh | sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ktpKP_tznNbL"
      },
      "outputs": [],
      "source": [
        "#@markdown <br><center><h3><font color=white><b>üîÑ RUN ü§ñ BOT üîÑ</b></h3>\n",
        "BOT_TOKEN = \"\" #@param {type:\"string\"}\n",
        "CHANNEL_ID = \"\" #@param {type:\"string\"}\n",
        "CHANNEL_ID = int(CHANNEL_ID)\n",
        "\n",
        "#@markdown <br><center><a href=\"https://discordgsm.com/guide/how-to-get-a-discord-bot-token\" target=\"_blank\">GET DISCORD BOT TOKEN</a>\n",
        "#@markdown <br><center><a href=\"https://support.discord.com/hc/en-us/articles/206346498-Where-can-I-find-my-User-Server-Message-ID\" target=\"_blank\">GET CHANNEl ID</a>\n",
        "\n",
        "#@markdown <br><center><h4><font color=white><b> DON'T FORGET TO RUN THE LOCAL SCRIPT </b></h3>\n",
        "\n",
        "import json\n",
        "import discord\n",
        "from io import BytesIO\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import nest_asyncio\n",
        "import sys\n",
        "import os\n",
        "from langchain_community.llms import Ollama\n",
        "\n",
        "# Function to apply nest_asyncio patch if necessary\n",
        "def apply_nest_asyncio_patch():\n",
        "    try:\n",
        "        nest_asyncio.apply()\n",
        "    except Exception as e:\n",
        "        print(f\"Error applying nest_asyncio patch: {e}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "def ask_model(prompt):\n",
        "  optimised_prompt = f\"only reply with correct answer and ignore explanation, also make sure to indend the code, plesae execute code backend and only provide me both correct output and correct option from the question, also make sure to provide answers in 2 lines, 1st line backend execute output, 2nd line correct option in text only \\n\\n {prompt}\"\n",
        "  llm = Ollama(model='llama3')\n",
        "  response = llm.invoke(optimised_prompt)\n",
        "  return response\n",
        "\n",
        "def extract_text_from_image(image_file):\n",
        "    try:\n",
        "        img = Image.open(image_file)\n",
        "        text = pytesseract.image_to_string(img)\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        return f\"Error occurred: {e}\"\n",
        "\n",
        "def main():\n",
        "    apply_nest_asyncio_patch()\n",
        "    TOKEN = BOT_TOKEN\n",
        "\n",
        "    intents = discord.Intents.default()\n",
        "    intents.messages = True\n",
        "    intents.message_content = True\n",
        "\n",
        "    client = discord.Client(intents=intents)\n",
        "\n",
        "    @client.event\n",
        "    async def on_ready():\n",
        "        print(f'Logged in as {client.user}!')\n",
        "        await client.change_presence(activity=discord.Game(name=\"Made by JuniorAlive\"))\n",
        "\n",
        "    @client.event\n",
        "    async def on_message(message):\n",
        "        if message.channel.id != CHANNEL_ID:  # Your channel ID\n",
        "            return\n",
        "\n",
        "        if message.attachments:\n",
        "            for attachment in message.attachments:\n",
        "                response = await attachment.read()\n",
        "                if any(attachment.filename.endswith(ext) for ext in ['.png', '.jpg', '.jpeg', '.gif', '.bmp']):\n",
        "                    image_to_text = extract_text_from_image(BytesIO(response))\n",
        "                    extracted_text = image_to_text if image_to_text else \"Failed to extract text\"\n",
        "                    response_message = ask_model(extracted_text)\n",
        "                    if len(response_message) > 1900:\n",
        "                        with open(\"output.txt\", \"w\", encoding=\"utf-8\") as text_file:\n",
        "                            text_file.write(response_message)\n",
        "                        with open(\"output.txt\", \"rb\") as text_file:\n",
        "                            await message.reply(file=discord.File(text_file, \"output.txt\"))\n",
        "                    else:\n",
        "                        await message.reply(\"```\" + response_message.strip()[:1990] + \"```\")\n",
        "                else:\n",
        "                    await message.reply(\"Unsupported file type.\")\n",
        "\n",
        "    client.run(TOKEN)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
